{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "!pip install selenium openpyxl"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: selenium in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (4.1.0)\n",
      "Requirement already satisfied: openpyxl in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (3.0.9)\n",
      "Requirement already satisfied: urllib3[secure]~=1.26 in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (from selenium) (0.19.0)\n",
      "Requirement already satisfied: et-xmlfile in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: idna in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.1)\n",
      "Requirement already satisfied: outcome in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: sniffio in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.0.0)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (from urllib3[secure]~=1.26->selenium) (21.0.0)\n",
      "Requirement already satisfied: certifi in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (from urllib3[secure]~=1.26->selenium) (2021.10.8)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (from urllib3[secure]~=1.26->selenium) (3.4.8)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (from cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (2.21)\n",
      "Requirement already satisfied: six>=1.5.2 in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.16.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/bobo/anaconda3/envs/ml/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.12.0)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import csv\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "from selenium import webdriver\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "import math\n",
    "import statistics\n",
    "import numpy as np\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def set_driver(url):\n",
    "    \n",
    "    ser = Service(DRIVER_PATH)\n",
    "    options = webdriver.ChromeOptions()  # Set up Chinese\n",
    "    # options.add_argument('--headless')\n",
    "    options.add_argument('lang=zh_CN.UTF-8')  # Replacement of head\n",
    "    options.add_argument(\n",
    "        'User-Agent=\"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.121 Safari/537.36\"')\n",
    "    options.add_argument(\"--disable-infobars\")\n",
    "    options.add_argument(\"--headless\")\n",
    "    # PROXY = \"11.456.448.110:8080\"\n",
    "    # options.add_argument('--proxy-server=%s' % PROXY)\n",
    "    driver = webdriver.Chrome(\n",
    "        service=ser,\n",
    "        options=options)\n",
    "\n",
    "    driver.get(url)\n",
    "    print(\"finish setup driver\")\n",
    "    return driver\n",
    "\n",
    "    \n",
    "def init_filename(source, subject):\n",
    "    # /呱吉/PTT.csv\n",
    "    # /呱吉/FB.csv\n",
    "    # ...\n",
    "    folder = f\"/{source}/\"\n",
    "    return subject + folder\n",
    "\n",
    "\n",
    "def write_file():\n",
    "    out_filename = \"\"\n",
    "    with open(out_filename, 'a') as out_file:\n",
    "        for line in in_file:\n",
    "\n",
    "            out_file.write(parsed_line)\n",
    "\n",
    "\n",
    "def init_csv(file_name):\n",
    "\n",
    "    with open(file_name, 'w+') as out_file:\n",
    "        write = csv.writer(out_file)\n",
    "        header = ['Source', 'Title', 'Link', 'Date', 'Summary', 'Text', 'Like']\n",
    "        # PTT, 呱吉吃大便, http://, '2021-11-17', XXXX, XXXXX, 23\n",
    "        write.writerow(header)\n",
    "\n",
    "\n",
    "def string_to_datetime(s):\n",
    "    return datetime.datetime.strptime(s, '%Y/%m/%d')\n",
    "\n",
    "def generate_ytr_name_list(filename=\"Youtuber名單 - 道歉.csv\"):\n",
    "    ytr_list = []\n",
    "    with open(filename, 'r') as f:\n",
    "        rows = csv.reader(f)\n",
    "        for row in rows:\n",
    "            if row[1] == \"\": pass\n",
    "            if row[1] == \"頻道(官方帳號)\": continue\n",
    "            ytr_name = []\n",
    "            ytr_name.append(row[1].split(\"\\n\")[0])\n",
    "\n",
    "            ytr_name.extend(row[3].replace(\"、\", \"\\n\").split(\"\\n\"))\n",
    "            ytr_list.append(list(set(ytr_name)))\n",
    "    return ytr_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## constant"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "DRIVER_PATH = '/home/bobo/Desktop/bobo/ML_final/bobo/crawlers/chromedriver'\n",
    "keywords_url = \"https://www.ettoday.net/news_search/doSearch.php?keywords=館長\"\n",
    "tag_url = \"https://www.ettoday.net/news/tag/統神/\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "ytr_list = [\"谷阿莫\", \"黃氏兄弟\", \"聖結石\", \"曾聖傑\"]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## tag"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def scroll_to_button(driver):\n",
    "    reached_page_end = False\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while not reached_page_end:\n",
    "        driver.find_element(By.XPATH,'//body').send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if last_height == new_height:\n",
    "            reached_page_end = True\n",
    "        else:\n",
    "            last_height = new_height\n",
    "    print(\"reach end\")\n",
    "    # driver.quit()\n",
    "    \n",
    "def crawl_page_tag(driver, filename):\n",
    "    block_div = driver.find_element(By.CLASS_NAME, \"c1\")\n",
    "    title_list = block_div.find_elements(By.XPATH,\n",
    "        \".//div[@class='piece clearfix']\")\n",
    "    \n",
    "    if title_list == []:\n",
    "        print(title_list)\n",
    "        print(\"is empty\")\n",
    "        return\n",
    "\n",
    "    press = title_list[-1].find_element(By.TAG_NAME,\n",
    "        \"h3\").find_element(By.TAG_NAME,\"a\")\n",
    "    press.send_keys(Keys.NULL)\n",
    "\n",
    "    print(\"len: \", len(title_list))\n",
    "\n",
    "    filename = filename\n",
    "    with open(filename, 'a') as f:\n",
    "        write = csv.writer(f)\n",
    "\n",
    "        header = ['Source', 'Title', 'Link', 'Date', 'Summary', 'Text', 'Like']\n",
    "        dic = {i: \"\" for i in header}\n",
    "\n",
    "        for i in title_list:\n",
    "            dic['Source'] = \"ettoday\"\n",
    "            dic['Title'] = i.find_element(By.TAG_NAME,'h3').text.replace(\"  \", \" \")\n",
    "            dic['Link'] = i.find_element(By.TAG_NAME, 'a').get_attribute(\"href\")\n",
    "            dic['Date'] = i.find_element(By.CLASS_NAME,'date').text\n",
    "            dic['Summary'] = i.find_element(By.CLASS_NAME,'summary').text\n",
    "            dic['Text'] = \"\"\n",
    "            dic['Like'] = 0\n",
    "\n",
    "            line = dic.values()\n",
    "            write.writerow(line)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# tag search\n",
    "def crawl_tag(path, tag_url):\n",
    "    driver = set_driver(tag_url)\n",
    "\n",
    "    scroll_to_button(driver)\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "    crawl_page_tag(driver, filename=path+\"ettoday_tag.csv\")\n",
    "\n",
    "    driver.quit()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## keywords"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def crawl_page_keyword(driver, filename):\n",
    "    block_div = driver.find_element(By.ID, \"primary\")\n",
    "    box_list = block_div.find_elements(By.CLASS_NAME, \"box_2\")\n",
    "    \n",
    "    if box_list == []:\n",
    "        print(\"is empty\")\n",
    "        return\n",
    "\n",
    "\n",
    "    filename = filename\n",
    "    with open(filename, 'a') as f:\n",
    "        write = csv.writer(f)\n",
    "\n",
    "        header = ['Source', 'Title', 'Link', 'Date', 'Summary', 'Text', 'Like']\n",
    "        dic = {i: \"\" for i in header}\n",
    "\n",
    "        for box in box_list:\n",
    "            dic['Source'] = \"ettoday\"\n",
    "            dic['Title'] = box.find_element(By.TAG_NAME, \"h2\").text.replace(\"\\u3000\", \" \")\n",
    "            dic['Link'] = box.find_element(By.TAG_NAME, 'a').get_attribute(\"href\")\n",
    "            dic['Date'] = box.find_element(By.CLASS_NAME, 'date').text.split(\"/ \")[1].replace(\")\", \"\")\n",
    "            dic['Summary'] = box.find_element(By.CLASS_NAME, 'detail').text\n",
    "            dic['Text'] = \"\"\n",
    "            dic['Like'] = 0\n",
    "\n",
    "            line = dic.values()\n",
    "            write.writerow(line)\n",
    "\n",
    "\n",
    "def check_exists_by_class(driver, class_name):\n",
    "    try:\n",
    "        driver.find_element(By.CLASS_NAME, class_name)\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def get_max_page(driver):\n",
    "    info = driver.find_element(By.CLASS_NAME, \"info\").text\n",
    "    for t in [\"第\", \"頁\", \"共\", \"頁\"]:\n",
    "        info = info.replace(t, \"\")\n",
    "    info = info.replace(\" \", \"\")\n",
    "    current_page, max_page = map(int, info.split(\"|\"))\n",
    "    current_page, max_page\n",
    "    return max_page\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# search by keywords\n",
    "def crawl_keyword(path, keywords_url):\n",
    "    driver = set_driver(keywords_url)\n",
    "\n",
    "    for i in range(get_max_page(driver)):\n",
    "        print(\"page \", i)\n",
    "        crawl_page_keyword(driver, filename=path+\"ettoday_keywords.csv\")\n",
    "        time.sleep(5)\n",
    "        next_page = driver.find_element(By.XPATH,\"//*[text()=' > ']\")\n",
    "        next_page.click()\n",
    "\n",
    "    driver.quit()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ytr crawling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "ytr_list = generate_ytr_name_list(\"Youtuber名單 - 道歉.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "base_path = \"data/\"\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)\n",
    "\n",
    "for ytr_name in ytr_list:\n",
    "    print(ytr_name)\n",
    "    folder_path = base_path + ytr_name[0] + \"/\"\n",
    "    \n",
    "    # if folder exists, next ytr\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    init_csv(folder_path+\"ettoday_tag.csv\")\n",
    "    init_csv(folder_path+\"ettoday_keywords.csv\")\n",
    "    \n",
    "    \n",
    "    for name in ytr_name:\n",
    "        keywords_url = \"https://www.ettoday.net/news_search/doSearch.php?keywords=\" + name\n",
    "        tag_url = \"https://www.ettoday.net/news/tag/\" + name + \"/\"\n",
    "    \n",
    "        crawl_tag(folder_path, tag_url)\n",
    "        crawl_keyword(folder_path, keywords_url)\n",
    "        \n",
    "    print(\"*\"*20)\n",
    "    print()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['芋圓柚子OEUR.studio', '阿神']\n",
      "['阿滴', '阿滴英文', '都省瑞']\n",
      "finish setup driver\n",
      "reach end\n",
      "len:  186\n",
      "finish setup driver\n",
      "page  0\n",
      "page  1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d35b18824a72466740eca9854c21d0838d2a95cb0ef047a5bc842bf6a70449"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}